# 消息存储

# 日志文件格式

一个 topic 可以认为一个一类消息，每个 topic 将被分成多个 partition，每个 partition 在存储层面是 append log 文件。

![Producer Topic 与 Partition](https://pic.imgdb.cn/item/607705e18322e6675c2f8ade.jpg)

在 Kafka 文件存储中，同一个 topic 下有多个不同 partition，每个 partition 为一个目录，partiton 命名规则为 topic 名称+有序序号，第一个 partiton 序号从 0 开始，序号最大值为 partitions 数量减 1。

![文件分区与分割](https://pic.imgdb.cn/item/607706098322e6675c2fe553.jpg)

- 每个 partion（目录）相当于一个巨型文件被平均分配到多个大小相等 segment（段）数据文件中。但每个段 segment file 消息数量不一定相等，这种特性方便 old segment file 快速被删除。
- 每个 partiton 只需要支持顺序读写就行了，segment 文件生命周期由服务端配置参数决定。

这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。

- segment file 组成：由 2 大部分组成，分别为 index file 和 data file，此 2 个文件一一对应，成对出现，后缀".index"和“.log”分别表示为 segment 索引文件、数据文件.
- segment 文件命名规则：partion 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。数值最大为 64 位 long 大小，20 位数字字符长度，没有数字用 0 填充。

![Segment 文件格式](https://pic.imgdb.cn/item/607706968322e6675c3140cd.jpg)

## Segment 索引与 Offset 查找

由于 Kafka 消息数据太大，如果全部建立索引，即占了空间又增加了耗时，所以 Kafka 选择了稀疏索引的方式，这样的话索引可以直接进入内存，加快偏查询速度。，通过 mmap 可以直接内存操作，稀疏索引为数据文件的每个对应 message 设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。Segment 中 index 与 data file 对应关系物理结构如下：

![Segment 中 index 与 data file 对应](https://pic.imgdb.cn/item/607706b98322e6675c3193c6.jpg)

上图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。其中以索引文件中元数据 3,497 为例，依次在数据文件中表示第 3 个 message（在全局 partiton 表示 offset 为 368772 的 message），以及该消息的物理偏移地址为 497。

查找某个 offset 的消息，先二分法找出消息所在的 segment 文件（因为每个 segment 的命名都是以该文件中消息 offset 最小的值命名）；然后，加载对应的.index 索引文件到内存，同样二分法找出小于等于给定 offset 的最大的那个 offset 记录（相对 offset，position）；最后，根据 position 到.log 文件中，顺序查找出 offset 等于给定 offset 值的消息。例如读取 offset=368776 的 message，需要通过下面 2 个步骤查找：

- 第一步查找 segment file，其中 00000000000000000000.index 表示最开始的文件，起始偏移量(offset)为 0。第二个文件 00000000000000368769.index 的消息量起始偏移量为 368770 = 368769 + 1.同样，第三个文件 00000000000000737337.index 的起始偏移量为 737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据 offset **二分查找**文件列表，就可以快速定位到具体文件。 当 offset=368776 时定位到 00000000000000368769.index|log

- 第二步通过 segment file 查找 message 通过第一步定位到 segment file，当 offset=368776 时，依次定位到 00000000000000368769.index 的元数据物理位置和 00000000000000368769.log 的物理偏移地址，然后再通过 00000000000000368769.log 顺序查找直到 offset=368776 为止。

上面讲的是如果要找某个 offset 的流程，但是我们大多数时候并不需要查找某个 offset,只需要按照顺序读即可，而在顺序读中，操作系统会对内存和磁盘之间添加 page cahe，也就是我们平常见到的预读操作，所以我们的顺序读操作时速度很快。但是 kafka 有个问题，如果分区过多，那么日志分段也会很多，写的时候由于是批量写，其实就会变成随机写了，随机 I/O 这个时候对性能影响很大。所以一般来说 Kafka 不能有太多的 partition。针对这一点，RocketMQ 把所有的日志都写在一个文件里面，就能变成顺序写，通过一定优化，读也能接近于顺序读。

## Message 物理结构

了解到 segment data file 由许多 message 组成，下面详细说明 message 物理结构如下：

![message 物理结构](https://pic.imgdb.cn/item/607707668322e6675c333389.jpg)

参数说明如下：

| 关键字              | 解释说明                                                                                                                                                                  |
| ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 8 byte offset       | 在 parition(分区)内的每条消息都有一个有序的 id 号，这个 id 号被称为偏移(offset),它可以唯一确定每条消息在 parition(分区)内的位置。即 offset 表示 partiion 的第多少 message |
| 4 byte message size | message 大小                                                                                                                                                              |
| 4 byte CRC32        | 用 crc32 校验 message                                                                                                                                                     |
| 1 byte “magic"      | 表示本次发布 Kafka 服务程序协议版本号                                                                                                                                     |
| 1 byte “attributes" | 表示为独立版本、或标识压缩类型、或编码类型。                                                                                                                              |
| 4 byte key length   | 表示 key 的长度,当 key 为-1 时，K byte key 字段不填                                                                                                                       |
| K byte key          | 可选                                                                                                                                                                      |
| value bytes payload | 表示实际消息数据。                                                                                                                                                        |
